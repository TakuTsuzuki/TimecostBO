{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "\n",
    "bounds = torch.stack([-torch.ones(d), torch.ones(d)])\n",
    "\n",
    "train_X = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(50, d)\n",
    "train_Y = 1 - torch.norm(train_X, dim=-1, keepdim=True)\n",
    "\n",
    "model = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.sampling import IIDNormalSampler\n",
    "\n",
    "sampler = IIDNormalSampler(num_samples=100, resample=True)\n",
    "qEI = qExpectedImprovement(model, best_f=train_Y.max(), sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "q = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim.initializers import initialize_q_batch_nonneg\n",
    "\n",
    "# generate a large number of random q-batches\n",
    "Xraw = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(100 * N, q, d)\n",
    "Yraw = qEI(Xraw)  # evaluate the acquisition function on these q-batches\n",
    "\n",
    "# apply the heuristic for sampling promising initial conditions\n",
    "X = initialize_q_batch_nonneg(Xraw, Yraw, N)\n",
    "\n",
    "# we'll want gradients for the input\n",
    "X.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  15/75 - Loss: -0.326\n",
      "Iteration  30/75 - Loss: -0.529\n",
      "Iteration  45/75 - Loss: -0.568\n",
      "Iteration  60/75 - Loss: -0.564\n",
      "Iteration  75/75 - Loss: -0.541\n"
     ]
    }
   ],
   "source": [
    "# set up the optimizer, make sure to only pass in the candidate set here\n",
    "optimizer = torch.optim.Adam([X], lr=0.01)\n",
    "X_traj = []  # we'll store the results\n",
    "\n",
    "# run a basic optimization loop\n",
    "for i in range(75):\n",
    "    optimizer.zero_grad()\n",
    "    # this performs batch evaluation, so this is an N-dim tensor\n",
    "    losses = - qEI(X)  # torch.optim minimizes\n",
    "    loss = losses.sum()\n",
    "    \n",
    "    loss.backward()  # perform backward pass\n",
    "    optimizer.step()  # take a step\n",
    "    \n",
    "    # clamp values to the feasible set\n",
    "    for j, (lb, ub) in enumerate(zip(*bounds)):\n",
    "        X.data[..., j].clamp_(lb, ub) # need to do this on the data not X itself\n",
    "    \n",
    "    # store the optimization trajecatory\n",
    "    X_traj.append(X.detach().clone())\n",
    "    \n",
    "    if (i + 1) % 15 == 0:\n",
    "        print(f\"Iteration {i+1:>3}/75 - Loss: {loss.item():>4.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47058266, 0.99794865, 0.49987686, 0.16786104, 0.13061285],\n",
       "       [0.06820774, 0.5556341 , 0.10346764, 0.13704604, 0.81089324],\n",
       "       [0.28773904, 0.948784  , 0.501875  , 0.7463471 , 0.60500836],\n",
       "       [0.29191488, 0.6558614 , 0.8919577 , 0.8561606 , 0.30511737],\n",
       "       [0.41843045, 0.800798  , 0.71512145, 0.5041714 , 0.6887779 ],\n",
       "       [0.20482177, 0.91034764, 0.43708825, 0.8872794 , 0.7380854 ],\n",
       "       [0.70153916, 0.47579175, 0.4672292 , 0.51348484, 0.09339857],\n",
       "       [0.7364302 , 0.85111195, 0.0241515 , 0.38854498, 0.39775878],\n",
       "       [0.30882168, 0.6236709 , 0.6571233 , 0.46451408, 0.562189  ],\n",
       "       [0.5001771 , 0.8483812 , 0.9488413 , 0.87194806, 0.6885145 ],\n",
       "       [0.68727106, 0.9938194 , 0.51558894, 0.53999126, 0.35124528],\n",
       "       [0.11529607, 0.84712875, 0.7916093 , 0.3952828 , 0.5187924 ],\n",
       "       [0.79604214, 0.8535609 , 0.6326108 , 0.06820387, 0.09980428],\n",
       "       [0.6581847 , 0.11283666, 0.77676135, 0.57432526, 0.76091045],\n",
       "       [0.09858644, 0.15066391, 0.12137771, 0.15978628, 0.44741213],\n",
       "       [0.7424205 , 0.20998085, 0.54109263, 0.9700042 , 0.5078516 ],\n",
       "       [0.8082206 , 0.5687096 , 0.75285363, 0.8997594 , 0.40116876],\n",
       "       [0.46103996, 0.15835637, 0.98513037, 0.92758805, 0.69948643],\n",
       "       [0.48480606, 0.18020588, 0.47500795, 0.7506764 , 0.7801759 ],\n",
       "       [0.68251425, 0.14447111, 0.9088746 , 0.35042018, 0.03113616],\n",
       "       [0.56255823, 0.68742776, 0.37468594, 0.44341308, 0.68212396],\n",
       "       [0.19586527, 0.49276996, 0.1831919 , 0.47170597, 0.6286057 ],\n",
       "       [0.6350633 , 0.21366346, 0.69503814, 0.04048824, 0.22202474],\n",
       "       [0.5423334 , 0.32840973, 0.65853727, 0.13175029, 0.2672879 ],\n",
       "       [0.15564358, 0.7993799 , 0.204     , 0.40492237, 0.5014027 ],\n",
       "       [0.66354346, 0.98478794, 0.23026383, 0.5480101 , 0.03448331],\n",
       "       [0.9809133 , 0.66816825, 0.23407799, 0.13483351, 0.4767645 ],\n",
       "       [0.22408485, 0.7585408 , 0.02007931, 0.43542224, 0.5930165 ],\n",
       "       [0.13564998, 0.9005014 , 0.7815783 , 0.13841075, 0.23529947],\n",
       "       [0.09113622, 0.5080531 , 0.68622077, 0.7527172 , 0.25623286],\n",
       "       [0.47600055, 0.11089796, 0.45805192, 0.32676858, 0.5811559 ],\n",
       "       [0.10286504, 0.64442325, 0.992764  , 0.38529724, 0.6865104 ],\n",
       "       [0.06985486, 0.3090729 , 0.04131746, 0.13921338, 0.29770786],\n",
       "       [0.6003284 , 0.879285  , 0.14375633, 0.33723295, 0.22970188],\n",
       "       [0.58562535, 0.7794786 , 0.114335  , 0.4079604 , 0.04543722],\n",
       "       [0.58561003, 0.8606477 , 0.91124034, 0.14010483, 0.2852046 ],\n",
       "       [0.13758147, 0.6521703 , 0.00613964, 0.71895146, 0.44587725],\n",
       "       [0.92105526, 0.23965967, 0.2079413 , 0.67520297, 0.2179904 ],\n",
       "       [0.5507393 , 0.71556336, 0.32818997, 0.87868863, 0.00157702],\n",
       "       [0.45609254, 0.11164242, 0.16250312, 0.06612313, 0.14853138],\n",
       "       [0.49101943, 0.13152474, 0.06798923, 0.47301352, 0.6973489 ],\n",
       "       [0.3341208 , 0.164823  , 0.8613311 , 0.4749533 , 0.8668221 ],\n",
       "       [0.7501262 , 0.7903874 , 0.11853218, 0.6679532 , 0.92220914],\n",
       "       [0.81107557, 0.16556025, 0.82522666, 0.816965  , 0.5477892 ],\n",
       "       [0.2626021 , 0.2678879 , 0.8548037 , 0.41551626, 0.9995958 ],\n",
       "       [0.19496268, 0.64839983, 0.37152344, 0.4414662 , 0.00170267],\n",
       "       [0.7607906 , 0.55647755, 0.7438155 , 0.33890843, 0.19582176],\n",
       "       [0.69736964, 0.9240002 , 0.82579625, 0.8243631 , 0.22295362],\n",
       "       [0.09285408, 0.42883676, 0.5653859 , 0.44511008, 0.8661836 ],\n",
       "       [0.33564347, 0.74911964, 0.02289182, 0.38262868, 0.5308485 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(torch.rand(50, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5755, 0.5888, 0.8243, 0.8729, 0.0501],\n",
       "         [0.1290, 0.8853, 0.9669, 0.5929, 0.4498]],\n",
       "\n",
       "        [[0.3573, 0.6302, 0.7881, 0.8128, 0.4783],\n",
       "         [0.3830, 0.0973, 0.2658, 0.7673, 0.1790]],\n",
       "\n",
       "        [[0.3010, 0.4046, 0.5424, 0.9651, 0.6443],\n",
       "         [0.2152, 0.1845, 0.9541, 0.8952, 0.1014]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0811, 0.9054, 0.3772, 0.2057, 0.9966],\n",
       "         [0.5297, 0.1481, 0.3191, 0.5470, 0.6809]],\n",
       "\n",
       "        [[0.6012, 0.5516, 0.5992, 0.8367, 0.7838],\n",
       "         [0.0425, 0.3714, 0.9717, 0.7650, 0.5864]],\n",
       "\n",
       "        [[0.0629, 0.8466, 0.8290, 0.1924, 0.3088],\n",
       "         [0.1591, 0.9698, 0.5169, 0.9902, 0.4205]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(100 * N, q, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1801,  0.0172, -0.8830,  0.8171,  0.6486],\n",
       "         [ 0.6180,  0.2402,  0.2326, -0.6120,  0.8851]],\n",
       "\n",
       "        [[ 0.9838,  0.4096,  0.4929, -0.9934,  0.7679],\n",
       "         [ 0.8102, -0.3548,  0.1331, -0.6534, -0.6121]],\n",
       "\n",
       "        [[ 0.3512, -0.1069, -0.2517,  0.0086,  0.5166],\n",
       "         [-0.7324, -0.8320, -0.2600,  0.4776,  0.0859]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4636, -0.4286,  0.5687, -0.1589,  0.0866],\n",
       "         [-0.7236, -0.0082,  0.1155, -0.6146,  0.3696]],\n",
       "\n",
       "        [[-0.5296,  0.2122,  0.8464,  0.7161,  0.3341],\n",
       "         [-0.0597, -0.9228, -0.3113, -0.7929,  0.4629]],\n",
       "\n",
       "        [[-0.5756, -0.1258,  0.6335, -0.8887, -0.4236],\n",
       "         [-0.5542, -0.6055, -0.6820, -0.9451,  0.0429]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xraw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Yraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
